{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zVU-eQKO_B1"
   },
   "source": [
    "# Project: Semantic Textual Similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joIJ7lxQs0Fx"
   },
   "source": [
    "### Mandatory project\n",
    "\n",
    "https://gebakx.github.io/ihlt/sts/index.html#5\n",
    "\n",
    "**Statement:**\n",
    "\n",
    "- Use data set and description of task Semantic Textual Similarity in SemEval 2012.\n",
    "\n",
    "- Implement some approaches to detect paraphrase using sentence similarity metrics.\n",
    "\n",
    "  - Explore some lexical dimensions.\n",
    "  - Explore the syntactic dimension alone.\n",
    "  - Explore the combination of both previous.\n",
    "\n",
    "- Add new components at your choice (optional)\n",
    "\n",
    "- Compare and comment the results achieved by these approaches among them and among the official results.\n",
    "\n",
    "- Send files to raco in IHLT STS Project before the oral presentation:\n",
    "\n",
    "  - Jupyter notebook: sts-[Student1]-[Student2].ipynb\n",
    "\n",
    "  - Slides: sts-[Student1]-[Student2].pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siyhifONwI5j"
   },
   "source": [
    "## Third Requirements libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNBxaXFBwMSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/guess/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/guess/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to /home/guess/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from nltk import CFG, ChartParser\n",
    "from nltk.book import FreqDist\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet as wn\n",
    "from scipy import spatial\n",
    "\n",
    "# nltk.download() # 1. d | 2. book | 3. q\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('conll2000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYak-oW7R4Y6"
   },
   "source": [
    "## Own Requirements libraries\n",
    "\n",
    "Here we are gonna  put our codes into modules (python files) to later just import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgUPMfLDR36I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n",
      "CPU times: user 4.54 s, sys: 565 ms, total: 5.1 s\n",
      "Wall time: 5.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# !curl -Lo models/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "\n",
    "from infersent import InferSent\n",
    "\n",
    "model_version = 2\n",
    "MODEL_PATH = f'./models_repo/infersent{model_version}.pkl'\n",
    "# W2V_PATH = './models_repo/glove.840B.300d.txt' # GloVe\n",
    "W2V_PATH = './models_repo/crawl-300d-2M.vec' # fastText\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "\n",
    "model_senteval = InferSent(params_model)\n",
    "model_senteval.load_state_dict(torch.load(MODEL_PATH))\n",
    "model_senteval.set_w2v_path(W2V_PATH)\n",
    "model_senteval.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7Edp8t-8zJs"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPG5VQQFpS6Q"
   },
   "source": [
    "## Download train/test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Y4JCsESbZy2R",
    "outputId": "9814e4c4-eb03-46a6-ff3d-56d63bab9685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "00-readme.txt\t   STS.gs.MSRvid.txt\t   STS.input.MSRvid.txt\n",
      "correlation.pl\t   STS.gs.SMTeuroparl.txt  STS.input.SMTeuroparl.txt\n",
      "STS.gs.MSRpar.txt  STS.input.MSRpar.txt    STS.output.MSRpar.txt\n",
      "\n",
      "Testing\n",
      "00-readme.txt\t   STS.gs.SMTeuroparl.txt\tSTS.input.MSRvid.txt\n",
      "STS.gs.ALL.txt\t   STS.gs.surprise.OnWN.txt\tSTS.input.SMTeuroparl.txt\n",
      "STS.gs.MSRpar.txt  STS.gs.surprise.SMTnews.txt\tSTS.input.surprise.OnWN.txt\n",
      "STS.gs.MSRvid.txt  STS.input.MSRpar.txt\t\tSTS.input.surprise.SMTnews.txt\n"
     ]
    }
   ],
   "source": [
    "url_train = 'https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train.tgz'\n",
    "url_test = 'https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/test-gold.tgz'\n",
    "\n",
    "!wget -q $url_train\n",
    "!wget -q $url_test\n",
    "\n",
    "with tarfile.open('train.tgz', \"r:gz\") as tar:\n",
    "  tar.extractall()\n",
    "with tarfile.open('test-gold.tgz', \"r:gz\") as tar:\n",
    "  tar.extractall()\n",
    "\n",
    "!echo 'Training' && ls train && echo '\\nTesting' && ls test-gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ji9wY0Ur88FA"
   },
   "source": [
    "## Read and gather metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6vhNkQ-z_Vx"
   },
   "source": [
    "Let's begin working with **MSRvid** data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ezCyFHPDuror",
    "outputId": "9790eff8-ad2d-47d5-b33c-c3787fc812b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train data set: (750, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone is drawing.</td>\n",
       "      <td>Someone is dancing.</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man and a woman are kissing each other.</td>\n",
       "      <td>A man and a woman are talking to each other.</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is slicing an onion.</td>\n",
       "      <td>A woman is cutting an onion.</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sent1  \\\n",
       "0                 A man is riding a bicycle.   \n",
       "1   A woman and man are dancing in the rain.   \n",
       "2                        Someone is drawing.   \n",
       "3  A man and a woman are kissing each other.   \n",
       "4               A woman is slicing an onion.   \n",
       "\n",
       "                                          sent2  score  \n",
       "0                       A man is riding a bike.    5.0  \n",
       "1          A man and woman are dancing in rain.    5.0  \n",
       "2                           Someone is dancing.    0.3  \n",
       "3  A man and a woman are talking to each other.    0.6  \n",
       "4                  A woman is cutting an onion.    4.2  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = pd.read_csv('train/STS.input.MSRvid.txt', sep='\\t', names=['sent1', 'sent2'])\n",
    "train_label = pd.read_csv('train/STS.gs.MSRvid.txt', names=['score'])\n",
    "train_data = pd.concat([train_sents, train_label], axis=1)\n",
    "\n",
    "test_sents = pd.read_csv('test-gold/STS.input.MSRvid.txt', sep='\\t', names=['sent1', 'sent2'])\n",
    "test_label = pd.read_csv('test-gold/STS.gs.MSRvid.txt', names=['score'])\n",
    "test_data = pd.concat([test_sents, test_label], axis=1)\n",
    "\n",
    "print(f' Train data set: ({len(train_data)}, {len(train_data.columns)})')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "pxauVKbtvPS8",
    "outputId": "20a2abfa-10c3-40f4-8c68-e53177deeac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test data set: (750, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>man hard hat dance</td>\n",
       "      <td>man wear hard hat dance</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>plane take</td>\n",
       "      <td>air plane take</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.971580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A child is riding a horse.</td>\n",
       "      <td>4.75</td>\n",
       "      <td>young child rid horse</td>\n",
       "      <td>child rid horse</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985212</td>\n",
       "      <td>0.984311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>man feed mouse snake</td>\n",
       "      <td>man feed mouse snake</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>3.80</td>\n",
       "      <td>man play large flute</td>\n",
       "      <td>man play flute</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.981777</td>\n",
       "      <td>0.984587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sent1  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1                A plane is taking off.   \n",
       "2      A young child is riding a horse.   \n",
       "3  A man is feeding a mouse to a snake.   \n",
       "4       A man is playing a large flute.   \n",
       "\n",
       "                                      sent2  score        sent1_processed  \\\n",
       "0      A man wearing a hard hat is dancing.   5.00     man hard hat dance   \n",
       "1               An air plane is taking off.   5.00             plane take   \n",
       "2                A child is riding a horse.   4.75  young child rid horse   \n",
       "3  The man is feeding a mouse to the snake.   5.00   man feed mouse snake   \n",
       "4                 A man is playing a flute.   3.80   man play large flute   \n",
       "\n",
       "           sent2_processed        ps       lch       wup       lin        dp  \\\n",
       "0  man wear hard hat dance  0.281250  0.357086  0.397059  0.310816  0.972126   \n",
       "1           air plane take  0.066667  0.127768  0.111111  0.044784  0.963400   \n",
       "2          child rid horse  0.019608  0.000000  0.000000  0.000000  0.985212   \n",
       "3     man feed mouse snake  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "4           man play flute  0.666667  0.666667  0.666667  0.666667  0.981777   \n",
       "\n",
       "      infer  \n",
       "0  0.981522  \n",
       "1  0.971580  \n",
       "2  0.984311  \n",
       "3  1.000000  \n",
       "4  0.984587  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f' Test data set: ({len(test_data)}, {len(test_data.columns)})')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lagd7mZjEY7i"
   },
   "source": [
    "**Check frequency of tokens**\n",
    "\n",
    "As shown in the result we should deal with stopwords as well as punctuations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "SThktq12Ct69",
    "outputId": "0561b9b5-e632-49c7-ce13-f2a70888c93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "[('.', 747), ('A', 588), ('is', 560), ('a', 396), ('man', 304), ('woman', 178)]\n",
      "Sentence 2:\n",
      "[('.', 749), ('A', 623), ('is', 575), ('a', 445), ('man', 302), ('woman', 192)]\n"
     ]
    }
   ],
   "source": [
    "sent1_tokens = train_data['sent1'].apply(nltk.word_tokenize).values\n",
    "sent2_tokens = train_data['sent2'].apply(nltk.word_tokenize).values\n",
    "\n",
    "freq_sent1 = FreqDist(np.concatenate(sent1_tokens).ravel())\n",
    "freq_sent2 = FreqDist(np.concatenate(sent2_tokens).ravel())\n",
    "\n",
    "print(f'Sentence 1:')\n",
    "print(freq_sent1.most_common()[:6])\n",
    "\n",
    "print(f'Sentence 2:')\n",
    "print(freq_sent2.most_common()[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "bTJpNLp-B50b",
    "outputId": "b39c518f-a7a0-4dfc-c750-e150d162c23d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent1     object\n",
       "sent2     object\n",
       "score    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t85Q-kW4kln"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Cast sentences as type string.\n",
    "- Deal with stopwords and puntuations\n",
    "- Tokenize the sentences.\n",
    "- Tag each word as a Part of speech (POS)\n",
    "- Lemmatize each word into its root but with sense (different than stemming).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpL2ZVHnLFHE"
   },
   "source": [
    "**Casting**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOFy0Jij8eh2"
   },
   "outputs": [],
   "source": [
    "# train_data[['sent1', 'sent2']] = train_data[['sent1', 'sent2']].astype(str) \n",
    "# print(train_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRCGUGw4LMod"
   },
   "source": [
    "**Stopwords and puntuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QTNFepY80S-D",
    "outputId": "56c4f4cd-db1f-4920-bd06-307ea6ae28ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man', 'riding', 'bicycle']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords and punctuations\n",
    "\n",
    "def get_stopwords():\n",
    "  stop_words = list(set(stopwords.words('english')))\n",
    "  stop_words_2 = [w.capitalize() for w in stop_words]\n",
    "  stop_words_3 = [w.upper() for w in stop_words]\n",
    "\n",
    "  stop_words_all = stop_words + stop_words_2 + stop_words_3\n",
    "\n",
    "  return stop_words_all\n",
    "\n",
    "def remove_stopwords(tokens, rm_punct=False, custom_chars=None):\n",
    "  \n",
    "  stop_words_all = get_stopwords()\n",
    "  result = [w for w in tokens if w not in stop_words_all]\n",
    "\n",
    "  if rm_punct:\n",
    "    result = [w for w in result if w not in punctuation]\n",
    "\n",
    "  if custom_chars is not None:  # custom characters to remove\n",
    "    result = [w for w in result if w not in custom_chars]\n",
    "\n",
    "  return result\n",
    "\n",
    "# Test\n",
    "s1 = 'A man is riding a bicycle.'\n",
    "remove_stopwords(nltk.word_tokenize(s1), rm_punct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTTsn8zzLRIk"
   },
   "source": [
    "**POS**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU1y4vjsLYt1"
   },
   "outputs": [],
   "source": [
    "def map_pos_wordnet(pos):\n",
    "  d = {\"N\": wordnet.NOUN, # 'n'\n",
    "       \"V\": wordnet.VERB, # 'v'\n",
    "       \"J\": wordnet.ADJ, #  'a'\n",
    "       \"R\": wordnet.ADV} #  'r'\n",
    "\n",
    "  return d[pos[0]]\n",
    "\n",
    "def lemmatize(pairs):\n",
    "  wnl = WordNetLemmatizer()\n",
    "  result = []\n",
    "  for token, pos in pairs:\n",
    "    if pos[0] in {'N','V', 'J', 'R'}:\n",
    "      synset = wnl.lemmatize(token.lower(), \n",
    "                                     pos=map_pos_wordnet(pos))\n",
    "      result.append(synset)\n",
    "    else:\n",
    "      result.append(token)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UaTl3iZn3Kpo",
    "outputId": "43fd5934-2234-42bf-a862-18df27f44946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a b'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_tokens(tokens):\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "join_tokens(['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_infersent(X, tokenize=True):\n",
    "    eb1 = model_senteval.encode([X[0]], tokenize=tokenize)\n",
    "    eb2 = model_senteval.encode([X[1]], tokenize=tokenize)\n",
    "\n",
    "    result = 1 - spatial.distance.cosine(eb1,eb2)\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zXQ6J-P7FN2"
   },
   "source": [
    "## Feature engineering\n",
    "\n",
    "Extract the most meaningful features from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Wu5EBlshsQI"
   },
   "outputs": [],
   "source": [
    "cols = ['sent1_processed', 'sent2_processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4w_QMTm9LzdG"
   },
   "source": [
    "**LCS distances + wsd lesk**\n",
    "\n",
    "There are some distances that do not exist because their synsets postag dont match (e.g n != v). For that case, a zero value is set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mJvfgUV1Wez"
   },
   "outputs": [],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "def lcs_distances(X):\n",
    "\n",
    "  results = []\n",
    "  for x in X:\n",
    "    result = []\n",
    "    context = dict(x).keys()\n",
    "    for (token, pos) in x:\n",
    "      # print(token, pos)\n",
    "      if pos[0] in {'N','V', 'J', 'R'}:\n",
    "        # synset = lesk(context, token.lower(), pos=map_pos_wordnet(pos))\n",
    "        synset = wn.synsets(token.lower(), pos=map_pos_wordnet(pos))\n",
    "        # print(synset)\n",
    "        # try if synset exists with pos tag\n",
    "        if len(synset) != 0:\n",
    "          result.append(synset[0])\n",
    "        else:\n",
    "          clean_token = token.lower().translate(str.maketrans('', '', punctuation))\n",
    "          synset = wn.synsets(clean_token)\n",
    "\n",
    "          # print(clean_token, synset) \n",
    "          if len(synset) != 0:\n",
    "            result.append(synset[0])\n",
    "          else: # default synset value\n",
    "            result.append(wn.synsets('default')[0])\n",
    "        # try if synset exists without pos tag\n",
    "      else:\n",
    "          # calculate lesk without considering pos\n",
    "        synset = wn.synsets(token.lower())\n",
    "        if len(synset) != 0:\n",
    "          # print(token, pos)\n",
    "          # print('here')\n",
    "          result.append(synset[0])\n",
    "        else: # For instance key-board\n",
    "          clean_token = token.lower().translate(str.maketrans('', '', punctuation))\n",
    "          synset = wn.synsets(clean_token)\n",
    "          if len(synset) != 0:\n",
    "            result.append(synset[0])\n",
    "          else: # default synset value\n",
    "            result.append(wn.synsets('default')[0])\n",
    "          # pass\n",
    "          # result.append(wn.synsets(''))\n",
    "    results.append(result)\n",
    "\n",
    "  # pairs_synsets\n",
    "  path_sims = []\n",
    "  lch_sims = []\n",
    "  wup_sims = []\n",
    "  lin_sims = []\n",
    "  for syn1, syn2 in zip(*results):\n",
    "    \n",
    "    # print(syn1, syn2)\n",
    "    ps = syn1.path_similarity(syn2)\n",
    "    # print('ps', ps)\n",
    "    try:\n",
    "      lch = syn1.lch_similarity(syn2)\n",
    "      lch_normalized = lch/syn1.lch_similarity(syn1)\n",
    "      wp = syn1.wup_similarity(syn2)\n",
    "      lin = syn1.lin_similarity(syn2, ic=brown_ic)\n",
    "\n",
    "      path_sims.append(ps)\n",
    "      lch_sims.append(lch_normalized)\n",
    "      wup_sims.append(wp)\n",
    "      lin_sims.append(lin)\n",
    "      # return [ps, lch_normalized, wp, lin]\n",
    "    except:\n",
    "      if ps is not None:\n",
    "        path_sims.append(ps)\n",
    "      else:\n",
    "        path_sims.append(0)\n",
    "      lch_sims.append(0)\n",
    "      wup_sims.append(0)\n",
    "      lin_sims.append(0)\n",
    "      # return [ps, 0, 0, 0]\n",
    "    # average_sim = (0.4*ps + 0.7*lch_normalized + 0.8*wp + 1*lin)/(2.9)\n",
    "\n",
    "  return np.array([np.mean(path_sims), np.mean(lch_sims), np.mean(wup_sims), np.mean(lin_sims)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXP4wbloL2dn"
   },
   "source": [
    "**Apply preprocessing steps**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "uejpXndGL00G",
    "outputId": "e789732c-beef-4d42-e67a-ae69a59410d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(man, NN), (rid, JJ), (bicycle, NN)]</td>\n",
       "      <td>[(man, NN), (rid, VBZ), (bike, IN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(woman, NN), (man, NN), (dance, NN), (rain, NN)]</td>\n",
       "      <td>[(man, NN), (woman, NN), (dance, NN), (rain, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone is drawing.</td>\n",
       "      <td>Someone is dancing.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[(someone, NN), (draw, NN)]</td>\n",
       "      <td>[(someone, NN), (dance, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man and a woman are kissing each other.</td>\n",
       "      <td>A man and a woman are talking to each other.</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[(man, NN), (woman, NN), (kiss, VB)]</td>\n",
       "      <td>[(man, NN), (woman, NN), (talk, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is slicing an onion.</td>\n",
       "      <td>A woman is cutting an onion.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>[(woman, NN), (slice, NN), (onion, NN)]</td>\n",
       "      <td>[(woman, NN), (cut, NN), (onion, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sent1  \\\n",
       "0                 A man is riding a bicycle.   \n",
       "1   A woman and man are dancing in the rain.   \n",
       "2                        Someone is drawing.   \n",
       "3  A man and a woman are kissing each other.   \n",
       "4               A woman is slicing an onion.   \n",
       "\n",
       "                                          sent2  score  \\\n",
       "0                       A man is riding a bike.    5.0   \n",
       "1          A man and woman are dancing in rain.    5.0   \n",
       "2                           Someone is dancing.    0.3   \n",
       "3  A man and a woman are talking to each other.    0.6   \n",
       "4                  A woman is cutting an onion.    4.2   \n",
       "\n",
       "                                     sent1_processed  \\\n",
       "0              [(man, NN), (rid, JJ), (bicycle, NN)]   \n",
       "1  [(woman, NN), (man, NN), (dance, NN), (rain, NN)]   \n",
       "2                        [(someone, NN), (draw, NN)]   \n",
       "3               [(man, NN), (woman, NN), (kiss, VB)]   \n",
       "4            [(woman, NN), (slice, NN), (onion, NN)]   \n",
       "\n",
       "                                     sent2_processed  \n",
       "0                [(man, NN), (rid, VBZ), (bike, IN)]  \n",
       "1  [(man, NN), (woman, NN), (dance, NN), (rain, NN)]  \n",
       "2                       [(someone, NN), (dance, NN)]  \n",
       "3               [(man, NN), (woman, NN), (talk, NN)]  \n",
       "4              [(woman, NN), (cut, NN), (onion, NN)]  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['sent1', 'sent2']:\n",
    "  train_data[col+'_processed'] = train_data[col].apply(nltk.word_tokenize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(lemmatize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  # train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "  # train_data[col+'_processed'] = train_data[col+'_processed'].apply(core_relationship)\n",
    "  \n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "-wYXjh-6ROe1",
    "outputId": "25b97261-2c89-401e-eb75-00f0db97acd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(man, NN), (rid, JJ), (bicycle, NN)]</td>\n",
       "      <td>[(man, NN), (rid, VBZ), (bike, IN)]</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(woman, NN), (man, NN), (dance, NN), (rain, NN)]</td>\n",
       "      <td>[(man, NN), (woman, NN), (dance, NN), (rain, NN)]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "\n",
       "                                  sent2  score  \\\n",
       "0               A man is riding a bike.    5.0   \n",
       "1  A man and woman are dancing in rain.    5.0   \n",
       "\n",
       "                                     sent1_processed  \\\n",
       "0              [(man, NN), (rid, JJ), (bicycle, NN)]   \n",
       "1  [(woman, NN), (man, NN), (dance, NN), (rain, NN)]   \n",
       "\n",
       "                                     sent2_processed        ps       lch  \\\n",
       "0                [(man, NN), (rid, VBZ), (bike, IN)]  0.733333  0.852518   \n",
       "1  [(man, NN), (woman, NN), (dance, NN), (rain, NN)]  0.666667  0.848992   \n",
       "\n",
       "        wup       lin  \n",
       "0  0.909091  0.666667  \n",
       "1  0.833333  0.893542  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs_wsd = train_data[cols].apply(lcs_distances, axis=1).values\n",
    "lcs_wsd = pd.DataFrame(np.stack(lcs_wsd), columns=['ps', 'lch', 'wup', 'lin'])\n",
    "train_data = pd.concat([train_data, lcs_wsd], axis=1)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHAGQesAMPqV"
   },
   "source": [
    "**Dependency Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ly7x1f72aS1N"
   },
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "from nltk.metrics.distance import jaro_similarity, jaro_winkler_similarity\n",
    "\n",
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "def dp_relationship(sent):\n",
    "\n",
    "#   results = []\n",
    "#   for x in X:\n",
    "#     result = []\n",
    "\n",
    "    parse = parser.raw_parse(sent)\n",
    "    tree = next(parse)\n",
    "    triples = list(tree.triples())\n",
    "    # print(triples1)\n",
    "    core_triples = list()\n",
    "    for (a,b,c) in triples:\n",
    "      # if b in ['nsubj']:\n",
    "      core_triples.append(c)\n",
    "      core_triples.append(a)\n",
    "      # if b in ['nmod']:\n",
    "      #   core_triples1.append(c)\n",
    "      #   core_triples1.append(a)\n",
    "      # elif b in ['dobj']:\n",
    "      #   core_triples1.append(c)\n",
    "      #   core_triples1.append(a)\n",
    "    # core_triples1 = [(c, a) for (a,b,c) in triples1 if b in ['nsubj']]\n",
    "    unique = []\n",
    "    [unique.append(item) for item in core_triples if item not in unique]\n",
    "\n",
    "    unique = [item for item in unique if 'V' in item[1] or 'N' in item[1] ]\n",
    "\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtoCvLJ_epqJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rid man bicycle</td>\n",
       "      <td>rid man bike</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>woman rain man dancing</td>\n",
       "      <td>man rain woman dancing</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.997711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone is drawing.</td>\n",
       "      <td>Someone is dancing.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>someone drawing</td>\n",
       "      <td>someone dancing</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.565121</td>\n",
       "      <td>0.949012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "2                       Someone is drawing.   \n",
       "\n",
       "                                  sent2  score         sent1_processed  \\\n",
       "0               A man is riding a bike.    5.0         rid man bicycle   \n",
       "1  A man and woman are dancing in rain.    5.0  woman rain man dancing   \n",
       "2                   Someone is dancing.    0.3         someone drawing   \n",
       "\n",
       "          sent2_processed        ps       lch       wup       lin     infer  \n",
       "0            rid man bike  0.733333  0.852518  0.909091  0.666667  0.988196  \n",
       "1  man rain woman dancing  0.666667  0.848992  0.833333  0.893542  0.997711  \n",
       "2         someone dancing  0.545455  0.670400  0.616071  0.565121  0.949012  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in ['sent1', 'sent2']:\n",
    "  train_data[col+'_processed'] = train_data[col].apply(nltk.word_tokenize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(dp_relationship)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(lemmatize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(lemmatize)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDRw8CGlLEzQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 108 ms, total: 1min 39s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>infer</th>\n",
       "      <th>dp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rid man bicycle</td>\n",
       "      <td>rid man bike</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.988608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>woman rain man dancing</td>\n",
       "      <td>man rain woman dancing</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.997711</td>\n",
       "      <td>0.994266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "\n",
       "                                  sent2  score         sent1_processed  \\\n",
       "0               A man is riding a bike.    5.0         rid man bicycle   \n",
       "1  A man and woman are dancing in rain.    5.0  woman rain man dancing   \n",
       "\n",
       "          sent2_processed        ps       lch       wup       lin     infer  \\\n",
       "0            rid man bike  0.733333  0.852518  0.909091  0.666667  0.988196   \n",
       "1  man rain woman dancing  0.666667  0.848992  0.833333  0.893542  0.997711   \n",
       "\n",
       "         dp  \n",
       "0  0.988608  \n",
       "1  0.994266  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depen_parsing = train_data[cols].apply(get_score_infersent, axis=1).values\n",
    "depen_parsing = pd.DataFrame(np.stack(depen_parsing), columns=['dp'])\n",
    "train_data = pd.concat([train_data, depen_parsing], axis=1)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7joapffRmKt"
   },
   "source": [
    "**SentEval: sentence embeddings**\n",
    "\n",
    "This function yields a score from  a pretrained model, based on word embedding.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "- Snippet: https://github.com/facebookresearch/InferSent/blob/master/demo.ipynb\n",
    "\n",
    "\n",
    "- Infersent1: https://drive.google.com/file/d/1pRbvodca415gtrbMJf8EqBf--wOmu9Lf/view?usp=sharing\n",
    "\n",
    "- Infersent2: https://drive.google.com/file/d/1sfIlbc8C5k_CujTF7UrtW_2lvNIH-EhW/view?usp=sharing\n",
    "\n",
    "- GloVe: http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "\n",
    "- Fasttext: https://fasttext.cc/docs/en/english-vectors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1Dur0fkVUNs"
   },
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "UdGtcl75z-ql",
    "outputId": "24208f60-a15d-47b2-9073-fef57e91c8e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>infer</th>\n",
       "      <th>dp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>man rid bicycle</td>\n",
       "      <td>man rid bike</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.988608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>woman man dance rain</td>\n",
       "      <td>man woman dance rain</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.997711</td>\n",
       "      <td>0.994266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone is drawing.</td>\n",
       "      <td>Someone is dancing.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>someone draw</td>\n",
       "      <td>someone dance</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.565121</td>\n",
       "      <td>0.949012</td>\n",
       "      <td>0.956376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "2                       Someone is drawing.   \n",
       "\n",
       "                                  sent2  score       sent1_processed  \\\n",
       "0               A man is riding a bike.    5.0       man rid bicycle   \n",
       "1  A man and woman are dancing in rain.    5.0  woman man dance rain   \n",
       "2                   Someone is dancing.    0.3          someone draw   \n",
       "\n",
       "        sent2_processed        ps       lch       wup       lin     infer  \\\n",
       "0          man rid bike  0.733333  0.852518  0.909091  0.666667  0.988196   \n",
       "1  man woman dance rain  0.666667  0.848992  0.833333  0.893542  0.997711   \n",
       "2         someone dance  0.545455  0.670400  0.616071  0.565121  0.949012   \n",
       "\n",
       "         dp  \n",
       "0  0.988608  \n",
       "1  0.994266  \n",
       "2  0.956376  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['sent1', 'sent2']:\n",
    "  train_data[col+'_processed'] = train_data[col].apply(nltk.word_tokenize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(lemmatize)\n",
    "  train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8o5s3b58_0We",
    "outputId": "de916d2e-65b7-4e57-b840-e7c706f38237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 18 ms, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>man rid bicycle</td>\n",
       "      <td>man rid bike</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988608</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>woman man dance rain</td>\n",
       "      <td>man woman dance rain</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.994266</td>\n",
       "      <td>0.997711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "\n",
       "                                  sent2  score       sent1_processed  \\\n",
       "0               A man is riding a bike.    5.0       man rid bicycle   \n",
       "1  A man and woman are dancing in rain.    5.0  woman man dance rain   \n",
       "\n",
       "        sent2_processed        ps       lch       wup       lin        dp  \\\n",
       "0          man rid bike  0.733333  0.852518  0.909091  0.666667  0.988608   \n",
       "1  man woman dance rain  0.666667  0.848992  0.833333  0.893542  0.994266   \n",
       "\n",
       "      infer  \n",
       "0  0.988196  \n",
       "1  0.997711  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "infer_feat = train_data[cols].apply(get_score_infersent, axis=1)\n",
    "infer_feat = pd.DataFrame(np.stack(infer_feat), columns=['infer'])\n",
    "train_data = pd.concat([train_data, infer_feat], axis=1)\n",
    "train_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBX00Y80McCA"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "Try a baseline model with the final features: basically the join of the scores (fom dependency tree, wds, lcs, etc).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "uLkAD_QsR6km",
    "outputId": "c377a66f-f730-462d-aa8a-983d51b08826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "      <td>A man is riding a bike.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>man rid bicycle</td>\n",
       "      <td>man rid bike</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988608</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman and man are dancing in the rain.</td>\n",
       "      <td>A man and woman are dancing in rain.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>woman man dance rain</td>\n",
       "      <td>man woman dance rain</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.994266</td>\n",
       "      <td>0.997711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent1  \\\n",
       "0                A man is riding a bicycle.   \n",
       "1  A woman and man are dancing in the rain.   \n",
       "\n",
       "                                  sent2  score       sent1_processed  \\\n",
       "0               A man is riding a bike.    5.0       man rid bicycle   \n",
       "1  A man and woman are dancing in rain.    5.0  woman man dance rain   \n",
       "\n",
       "        sent2_processed        ps       lch       wup       lin        dp  \\\n",
       "0          man rid bike  0.733333  0.852518  0.909091  0.666667  0.988608   \n",
       "1  man woman dance rain  0.666667  0.848992  0.833333  0.893542  0.994266   \n",
       "\n",
       "      infer  \n",
       "0  0.988196  \n",
       "1  0.997711  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EMaMwozaSMQm",
    "outputId": "40a4f84b-6b9b-4407-b6be-eb83a5a76503"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988608</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.893542</td>\n",
       "      <td>0.994266</td>\n",
       "      <td>0.997711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.565121</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.949012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.966544</td>\n",
       "      <td>0.965816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.899328</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.896518</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.973691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ps       lch       wup       lin        dp     infer\n",
       "0  0.733333  0.852518  0.909091  0.666667  0.988608  0.988196\n",
       "1  0.666667  0.848992  0.833333  0.893542  0.994266  0.997711\n",
       "2  0.545455  0.670400  0.616071  0.565121  0.956376  0.949012\n",
       "3  0.700000  0.666667  0.666667  0.666667  0.966544  0.965816\n",
       "4  0.777778  0.899328  0.952381  0.896518  0.969697  0.973691"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'score'\n",
    "features = [col for col in train_data.columns if col not in ['sent1',\n",
    "                                                             'sent2',\n",
    "                                                             'sent1_processed',\n",
    "                                                             'sent2_processed', label]]\n",
    "X = train_data[features].copy()\n",
    "y = train_data[label].copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBuSc_qUe-J3"
   },
   "source": [
    "Scaling all the features with mean 0 and  variance 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "1ebXuX2oe2R7",
    "outputId": "490cbffb-2003-4387-ca58-fef103c6f77e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.18323415,  1.38163171,  1.57551857,  0.78430307,  1.4622357 ,\n",
       "         1.45028039],\n",
       "       [ 0.92769299,  1.36638544,  1.26103385,  1.62937857,  1.61550423,\n",
       "         1.71021049],\n",
       "       [ 0.46307271,  0.59420698,  0.3591366 ,  0.40606107,  0.58917887,\n",
       "         0.37986533],\n",
       "       ...,\n",
       "       [-0.87529182, -1.00240112, -1.0148424 , -1.02143676, -0.66109013,\n",
       "        -1.0396785 ],\n",
       "       [-0.35001278, -0.86317465, -0.81456529, -0.45731164, -0.98033983,\n",
       "        -1.0114637 ],\n",
       "       [-1.29941916, -0.93431276, -0.85231418, -1.60907969, -0.93611198,\n",
       "        -0.62109228]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X) # This scaler will be used for training stage\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "xqdYvMoSUxKu",
    "outputId": "1614b671-b0b6-466c-a05f-dd89bfa89dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10608713, -0.33423724, -0.16339693, -0.23559656, -0.37275342,\n",
       "        -0.16818849],\n",
       "       [ 0.1741742 ,  0.56777252,  0.61309549,  0.63740837, -0.21067452,\n",
       "        -0.225385  ],\n",
       "       [-0.00929124, -0.1318443 ,  0.23970729,  0.28896042,  0.75875071,\n",
       "         0.6998919 ],\n",
       "       ...,\n",
       "       [ 1.0075496 ,  0.92078266,  0.86047963,  0.78430307,  0.86112993,\n",
       "         0.94728426],\n",
       "       [-1.35129183, -1.11172159, -1.64015374, -1.69892634,  0.19052118,\n",
       "        -0.10698968],\n",
       "       [ 0.52840994,  0.74846772,  0.93658719,  0.53193149, -0.5444661 ,\n",
       "        -0.62639233]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_scaled, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8OecD5gm1k3"
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "YtM6IB6bMshf",
    "outputId": "84a8070e-014d-44df-9329-53c6868a9124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'GradientBoostingRegressor', 'mean': 0.638, 'std': 0.029}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
    "#           'learning_rate': 0.01, 'loss': 'ls'}\n",
    "params = {'n_estimators': [100], 'seed':[seed]}\n",
    "model = XGBRegressor()\n",
    "for k, v in model.get_params().items():\n",
    "    if k not in list(params.keys()):\n",
    "        params[k] = [v]\n",
    "\n",
    "\n",
    "scoring = 'r2'\n",
    "num_folds = 5\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid_search_t = GridSearchCV(model, params, n_jobs=-1,\n",
    "                             verbose=1, cv=kfold, return_train_score=True,\n",
    "                                         scoring=scoring)\n",
    "grid_search_t.fit(X_train, y_train)\n",
    "\n",
    "mean = grid_search_t.cv_results_['mean_test_score'][0]\n",
    "std = grid_search_t.cv_results_['std_test_score'][0]\n",
    "\n",
    "name = 'GradientBoostingRegressor'\n",
    "d = {'name': name, 'mean': round(mean, 3),\n",
    "                 'std': round(std, 3)}\n",
    "\n",
    "#Base model\n",
    "\n",
    "estimator = grid_search_t.best_estimator_\n",
    "\n",
    "d\n",
    "# clf.fit(X_train, y_train)\n",
    "# mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "# print(\"MSE: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:52:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_scaled, y.values)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWFNElFAWicv"
   },
   "source": [
    "## Tuning\n",
    "\n",
    "Search the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gH3xYBvZqK7L"
   },
   "outputs": [],
   "source": [
    "# !pip install hyperopt, hpsklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:42:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s, best loss: 0.5450839130169012]\n",
      "[10:42:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s, best loss: 0.5450839130169012]\n",
      "[10:42:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s, best loss: 0.5450839130169012]\n",
      "[10:42:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.83it/s, best loss: 0.5450839130169012]\n",
      "[10:42:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s, best loss: 0.3678839733682103]\n",
      "[10:42:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s, best loss: 0.3678839733682103]\n",
      "[10:42:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s, best loss: 0.3678839733682103]\n",
      "[10:42:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it, best loss: 0.3678839733682103]\n",
      "[10:42:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it, best loss: 0.3678839733682103]\n",
      "[10:42:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s, best loss: 0.3678839733682103]\n",
      "[10:42:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it, best loss: 0.36478464270912503]\n",
      "[10:42:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s, best loss: 0.36478464270912503]\n",
      "[10:42:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it, best loss: 0.36478464270912503]\n",
      "[10:42:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it, best loss: 0.36478464270912503]\n",
      "[10:42:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s, best loss: 0.36478464270912503]\n",
      "[10:42:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it, best loss: 0.36478464270912503]\n",
      "[10:42:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/it, best loss: 0.36478464270912503]\n",
      "[10:42:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it, best loss: 0.36478464270912503]\n",
      "[10:42:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s, best loss: 0.36478464270912503]\n",
      "[10:42:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s, best loss: 0.36478464270912503]\n",
      "[10:42:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s, best loss: 0.36478464270912503]\n",
      "[10:42:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.11it/s, best loss: 0.36478464270912503]\n",
      "[10:42:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s, best loss: 0.36478464270912503]\n",
      "[10:42:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.92it/s, best loss: 0.36478464270912503]\n",
      "[10:42:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it, best loss: 0.36478464270912503]\n",
      "[10:42:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s, best loss: 0.36478464270912503]\n",
      "[10:42:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it, best loss: 0.3595402861895187]\n",
      "[10:42:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it, best loss: 0.3595402861895187]\n",
      "[10:42:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it, best loss: 0.3595402861895187]\n",
      "[10:42:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it, best loss: 0.3595402861895187]\n",
      "[10:42:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it, best loss: 0.3595402861895187]\n",
      "[10:42:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it, best loss: 0.3595402861895187]\n",
      "[10:42:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.99it/s, best loss: 0.3595402861895187]\n",
      "[10:42:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it, best loss: 0.3595402861895187]\n",
      "[10:42:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/it, best loss: 0.3595402861895187]\n",
      "[10:42:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it, best loss: 0.3595402861895187]\n",
      "[10:42:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it, best loss: 0.34469675255194143]\n",
      "[10:42:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s, best loss: 0.34469675255194143]\n",
      "[10:42:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s, best loss: 0.34469675255194143]\n",
      "[10:42:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s, best loss: 0.34469675255194143]\n",
      "[10:42:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s, best loss: 0.34469675255194143]\n",
      "[10:42:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.52it/s, best loss: 0.34469675255194143]\n",
      "[10:42:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s, best loss: 0.34469675255194143]\n",
      "[10:42:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s, best loss: 0.34469675255194143]\n",
      "[10:42:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it, best loss: 0.34469675255194143]\n",
      "[10:42:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s, best loss: 0.34469675255194143]\n",
      "[10:42:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it, best loss: 0.34469675255194143]\n",
      "[10:42:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s, best loss: 0.34469675255194143]\n",
      "[10:42:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s, best loss: 0.34469675255194143]\n",
      "[10:42:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s, best loss: 0.34469675255194143]\n",
      "[10:42:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s, best loss: 0.34469675255194143]\n",
      "[10:42:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.90it/s, best loss: 0.34469675255194143]\n",
      "[10:42:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s, best loss: 0.34469675255194143]\n",
      "[10:42:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it, best loss: 0.34469675255194143]\n",
      "[10:42:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s, best loss: 0.34469675255194143]\n",
      "[10:43:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s, best loss: 0.34469675255194143]\n",
      "[10:43:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s, best loss: 0.34469675255194143]\n",
      "[10:43:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.93it/s, best loss: 0.34469675255194143]\n",
      "[10:43:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s, best loss: 0.34469675255194143]\n",
      "[10:43:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it, best loss: 0.34469675255194143]\n",
      "[10:43:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s, best loss: 0.34469675255194143]\n",
      "[10:43:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s, best loss: 0.34469675255194143]\n",
      "[10:43:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s, best loss: 0.34469675255194143]\n",
      "[10:43:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.56it/s, best loss: 0.34469675255194143]\n",
      "[10:43:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it, best loss: 0.34469675255194143]\n",
      "[10:43:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s, best loss: 0.34469675255194143]\n",
      "[10:43:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it, best loss: 0.34469675255194143]\n",
      "[10:43:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s, best loss: 0.34469675255194143]\n",
      "[10:43:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s, best loss: 0.34343936655501317]\n",
      "[10:43:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s, best loss: 0.34343936655501317]\n",
      "[10:43:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.93it/s, best loss: 0.34343936655501317]\n",
      "[10:43:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s, best loss: 0.34343936655501317]\n",
      "[10:43:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s, best loss: 0.34343936655501317]\n",
      "[10:43:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s, best loss: 0.34343936655501317]\n",
      "[10:43:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s, best loss: 0.34343936655501317]\n",
      "[10:43:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it, best loss: 0.34343936655501317]\n",
      "[10:43:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s, best loss: 0.34343936655501317]\n",
      "[10:43:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it, best loss: 0.34343936655501317]\n",
      "[10:43:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it, best loss: 0.33863483204521105]\n",
      "[10:43:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it, best loss: 0.33863483204521105]\n",
      "[10:43:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.6569381722285799\n",
      "{'learner': XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "             colsample_bylevel=0.9435787197217484, colsample_bynode=1,\n",
      "             colsample_bytree=0.9788735935838796, gamma=0.01828207589799718,\n",
      "             importance_type='gain', learning_rate=0.00195164560932182,\n",
      "             max_delta_step=0, max_depth=8, min_child_weight=12, missing=nan,\n",
      "             n_estimators=4600, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "             random_state=0, reg_alpha=0.008417303870082648,\n",
      "             reg_lambda=3.9591016185199215, scale_pos_weight=1, seed=1,\n",
      "             silent=None, subsample=0.8300232906261146, verbosity=1), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, xgboost_regression, any_regressor, any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "# estim = HyperoptEstimator(regressor=xgboost_regression('my_clf'),\n",
    "estim = HyperoptEstimator(regressor=xgboost_regression('my_clf'),                          \n",
    "#                           preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=80,\n",
    "                          trial_timeout=300)\n",
    "\n",
    "estim.fit( X_train, y_train.values )\n",
    "print(estim.score(X_val, y_val.values))\n",
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YHLFJdffuRVT",
    "outputId": "13d3a331-7053-4e22-da88-be86e38df828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "             colsample_bylevel=0.9435787197217484, colsample_bynode=1,\n",
       "             colsample_bytree=0.9788735935838796, gamma=0.01828207589799718,\n",
       "             importance_type='gain', learning_rate=0.00195164560932182,\n",
       "             max_delta_step=0, max_depth=8, min_child_weight=12, missing=nan,\n",
       "             n_estimators=4600, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random_state=0, reg_alpha=0.008417303870082648,\n",
       "             reg_lambda=3.9591016185199215, scale_pos_weight=1, seed=1,\n",
       "             silent=None, subsample=0.8300232906261146, verbosity=1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_final = estim.best_model()['learner']\n",
    "best_model_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LvjtXv-OaYM"
   },
   "source": [
    "Once we decide the best model, we need to retrain  the model with all the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Gl9E4YECOM-X",
    "outputId": "5965387b-47c7-4c6d-cbec-fbaa7444bfe8"
   },
   "outputs": [],
   "source": [
    "# params_new_t = xgb_opt[0]\n",
    "# params_new_t.update({'n_estimators': 1000})\n",
    "# model = XGBRegressor()\n",
    "# params_new = dict()\n",
    "# # for k, v in model.get_params().items():\n",
    "# #     params_new[k] = [v]\n",
    "# for k, v in params_new_t.items():\n",
    "#     params_new[k] = [v]\n",
    "\n",
    "# grid_search_t = GridSearchCV(model, params_new, n_jobs=-1,\n",
    "#                              verbose=1, cv=kfold, return_train_score=True,\n",
    "#                                          scoring=scoring)\n",
    "# grid_search_t.fit(X_scaled, y)\n",
    "# best_model_final = grid_search_t.best_estimator_\n",
    "# best_model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMq4FjOdtVCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "             colsample_bylevel=0.9435787197217484, colsample_bynode=1,\n",
       "             colsample_bytree=0.9788735935838796, gamma=0.01828207589799718,\n",
       "             importance_type='gain', learning_rate=0.00195164560932182,\n",
       "             max_delta_step=0, max_depth=8, min_child_weight=12, missing=nan,\n",
       "             n_estimators=4600, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random_state=0, reg_alpha=0.008417303870082648,\n",
       "             reg_lambda=3.9591016185199215, scale_pos_weight=1, seed=1,\n",
       "             silent=None, subsample=0.8300232906261146, verbosity=1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_final.fit(X_scaled, y.values)\n",
    "best_model_final            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAudDtdYEKus"
   },
   "source": [
    "## Testing\n",
    "\n",
    "We need to apply all the preprocessing and feature engineering steps to the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWHu-1hsXPoZ"
   },
   "source": [
    "**LCS + WSD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "j8xcmAXJVj3I",
    "outputId": "93ea037e-2e04-4581-b81d-81d5e6d572ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(man, NN), (hard, JJ), (hat, WP), (dance, NN)]</td>\n",
       "      <td>[(man, NN), (wear, VB), (hard, JJ), (hat, DT),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(plane, NN), (take, VB)]</td>\n",
       "      <td>[(air, NN), (plane, NNS), (take, VBP)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sent1                                 sent2  \\\n",
       "0  A man with a hard hat is dancing.  A man wearing a hard hat is dancing.   \n",
       "1             A plane is taking off.           An air plane is taking off.   \n",
       "\n",
       "   score                                  sent1_processed  \\\n",
       "0    5.0  [(man, NN), (hard, JJ), (hat, WP), (dance, NN)]   \n",
       "1    5.0                        [(plane, NN), (take, VB)]   \n",
       "\n",
       "                                     sent2_processed  \n",
       "0  [(man, NN), (wear, VB), (hard, JJ), (hat, DT),...  \n",
       "1             [(air, NN), (plane, NNS), (take, VBP)]  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['sent1', 'sent2']:\n",
    "  test_data[col+'_processed'] = test_data[col].apply(nltk.word_tokenize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(lemmatize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  # train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "  # train_data[col+'_processed'] = train_data[col+'_processed'].apply(core_relationship)\n",
    "  \n",
    "\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "087XLAMLVz0m",
    "outputId": "83d8d875-ec0e-46bc-92ec-5db2d95fc539"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(man, NN), (hard, JJ), (hat, WP), (dance, NN)]</td>\n",
       "      <td>[(man, NN), (wear, VB), (hard, JJ), (hat, DT),...</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(plane, NN), (take, VB)]</td>\n",
       "      <td>[(air, NN), (plane, NNS), (take, VBP)]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sent1                                 sent2  \\\n",
       "0  A man with a hard hat is dancing.  A man wearing a hard hat is dancing.   \n",
       "1             A plane is taking off.           An air plane is taking off.   \n",
       "\n",
       "   score                                  sent1_processed  \\\n",
       "0    5.0  [(man, NN), (hard, JJ), (hat, WP), (dance, NN)]   \n",
       "1    5.0                        [(plane, NN), (take, VB)]   \n",
       "\n",
       "                                     sent2_processed        ps       lch  \\\n",
       "0  [(man, NN), (wear, VB), (hard, JJ), (hat, DT),...  0.281250  0.357086   \n",
       "1             [(air, NN), (plane, NNS), (take, VBP)]  0.066667  0.127768   \n",
       "\n",
       "        wup       lin  \n",
       "0  0.397059  0.310816  \n",
       "1  0.111111  0.044784  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs_wsd_test = test_data[cols].apply(lcs_distances, axis=1).values\n",
    "lcs_wsd_test = pd.DataFrame(np.stack(lcs_wsd_test), columns=['ps', 'lch', 'wup', 'lin'])\n",
    "test_data = pd.concat([test_data, lcs_wsd_test], axis=1)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependency trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtoCvLJ_epqJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 423 ms, total: 14.6 s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>man dancing hat</td>\n",
       "      <td>wear man dancing hat</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>plane taking</td>\n",
       "      <td>plane take air</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A child is riding a horse.</td>\n",
       "      <td>4.75</td>\n",
       "      <td>child rid horse</td>\n",
       "      <td>rid child horse</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sent1                                 sent2  \\\n",
       "0  A man with a hard hat is dancing.  A man wearing a hard hat is dancing.   \n",
       "1             A plane is taking off.           An air plane is taking off.   \n",
       "2   A young child is riding a horse.            A child is riding a horse.   \n",
       "\n",
       "   score  sent1_processed       sent2_processed        ps       lch       wup  \\\n",
       "0   5.00  man dancing hat  wear man dancing hat  0.281250  0.357086  0.397059   \n",
       "1   5.00     plane taking        plane take air  0.066667  0.127768  0.111111   \n",
       "2   4.75  child rid horse       rid child horse  0.019608  0.000000  0.000000   \n",
       "\n",
       "        lin  \n",
       "0  0.310816  \n",
       "1  0.044784  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in ['sent1', 'sent2']:\n",
    "  test_data[col+'_processed'] = test_data[col].apply(nltk.word_tokenize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(join_tokens)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(dp_relationship)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(lemmatize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(join_tokens)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(lemmatize)\n",
    "#   train_data[col+'_processed'] = train_data[col+'_processed'].apply(join_tokens)\n",
    "\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDRw8CGlLEzQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 0 ns, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>man dancing hat</td>\n",
       "      <td>wear man dancing hat</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "      <td>0.972126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>plane taking</td>\n",
       "      <td>plane take air</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sent1                                 sent2  \\\n",
       "0  A man with a hard hat is dancing.  A man wearing a hard hat is dancing.   \n",
       "1             A plane is taking off.           An air plane is taking off.   \n",
       "\n",
       "   score  sent1_processed       sent2_processed        ps       lch       wup  \\\n",
       "0    5.0  man dancing hat  wear man dancing hat  0.281250  0.357086  0.397059   \n",
       "1    5.0     plane taking        plane take air  0.066667  0.127768  0.111111   \n",
       "\n",
       "        lin        dp  \n",
       "0  0.310816  0.972126  \n",
       "1  0.044784  0.963400  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depen_parsing_test = test_data[cols].apply(get_score_infersent, axis=1).values\n",
    "depen_parsing_test = pd.DataFrame(np.stack(depen_parsing_test), columns=['dp'])\n",
    "test_data = pd.concat([test_data, depen_parsing_test], axis=1)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGUZyOlCXTPg"
   },
   "source": [
    "**SentEval word embedding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "-XlqjYRwXTmd",
    "outputId": "f447736c-8324-4dae-d7c8-25f71adcd96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 7.26 ms, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_processed</th>\n",
       "      <th>sent2_processed</th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>man hard hat dance</td>\n",
       "      <td>man wear hard hat dance</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>plane take</td>\n",
       "      <td>air plane take</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.971580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sent1                                 sent2  \\\n",
       "0  A man with a hard hat is dancing.  A man wearing a hard hat is dancing.   \n",
       "1             A plane is taking off.           An air plane is taking off.   \n",
       "\n",
       "   score     sent1_processed          sent2_processed        ps       lch  \\\n",
       "0    5.0  man hard hat dance  man wear hard hat dance  0.281250  0.357086   \n",
       "1    5.0          plane take           air plane take  0.066667  0.127768   \n",
       "\n",
       "        wup       lin        dp     infer  \n",
       "0  0.397059  0.310816  0.972126  0.981522  \n",
       "1  0.111111  0.044784  0.963400  0.971580  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in ['sent1', 'sent2']:\n",
    "  test_data[col+'_processed'] = test_data[col].apply(nltk.word_tokenize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(remove_stopwords, \n",
    "                                                                    rm_punct=True)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(nltk.pos_tag)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(lemmatize)\n",
    "  test_data[col+'_processed'] = test_data[col+'_processed'].apply(join_tokens)\n",
    "\n",
    "infer_feat_test = test_data[cols].apply(get_score_infersent, axis=1)\n",
    "infer_feat_test = pd.DataFrame(np.stack(infer_feat_test), columns=['infer'])\n",
    "test_data = pd.concat([test_data, infer_feat_test], axis=1)\n",
    "test_data.head(2)                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ZrNsNhmuaslj",
    "outputId": "e2c9217d-6dd4-4106-eeb2-23313403ab6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps</th>\n",
       "      <th>lch</th>\n",
       "      <th>wup</th>\n",
       "      <th>lin</th>\n",
       "      <th>dp</th>\n",
       "      <th>infer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.310816</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.971580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985212</td>\n",
       "      <td>0.984311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.981777</td>\n",
       "      <td>0.984587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ps       lch       wup       lin        dp     infer\n",
       "0  0.281250  0.357086  0.397059  0.310816  0.972126  0.981522\n",
       "1  0.066667  0.127768  0.111111  0.044784  0.963400  0.971580\n",
       "2  0.019608  0.000000  0.000000  0.000000  0.985212  0.984311\n",
       "3  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "4  0.666667  0.666667  0.666667  0.666667  0.981777  0.984587"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data[features].copy()\n",
    "y_test = test_data[label].copy()\n",
    "print(len(X_test))\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB_z-pMRhBSo"
   },
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "jbtqGl3vhCl8",
    "outputId": "3abd540c-939f-4d67-c155-5f9b9819b6ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.54965431, -0.76047294, -0.55002815, -0.54118683,  1.01578855,\n",
       "         1.26796703],\n",
       "       [-1.3721774 , -1.75197984, -1.7370538 , -1.53211258,  0.77943903,\n",
       "         0.99636543],\n",
       "       [-1.5525594 , -2.3044135 , -2.19829805, -1.69892634,  1.37027329,\n",
       "         1.34415251],\n",
       "       ...,\n",
       "       [-1.28699702, -0.8620756 , -0.45597389, -0.93892809, -2.39806082,\n",
       "        -2.49509654],\n",
       "       [-1.4147676 , -1.57308315, -1.32436157, -1.69892634, -1.34660563,\n",
       "        -1.274227  ],\n",
       "       [-1.3469041 , -1.20917208, -0.92987635, -1.24845432, -1.21460018,\n",
       "        -1.18490132]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.8193848744629275\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_final.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(f'Pearson correlation: {pearsonr(y_test.values, y_pred)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i785FTb_nUPu",
    "outputId": "7020c6dc-54cc-4256-9a4f-9295a1885b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.8258677130097921\n"
     ]
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(f'Pearson correlation: {pearsonr(y_test.values, y_pred)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_my7k3BchO25",
    "outputId": "e00fb158-79f7-49f4-c7b8-c5b92b219fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.8183213591853379\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(f'Pearson correlation: {pearsonr(y_test.values, y_pred)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXLwReupF3AK"
   },
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(pd.Series(best_model_final.feature_importances_, index=X.columns)\n",
    "   .nlargest(10)\n",
    "   .plot(kind='barh')) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiSEbuGzDVVl"
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gW13ET70xJI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a-AE7IkZWmun",
    "R4FeOQeyPgRf"
   ],
   "name": "sts_Gusseppe_Bravo_Arthur_Muller.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
