{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp_classes.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Eeh3HhMkxQiy","colab_type":"text"},"source":["# Document structure\n"]},{"cell_type":"markdown","metadata":{"id":"d_YtLgQfxTL0","colab_type":"text"},"source":["## searching textual zones\n","\n","There are several types of types of sctrutures, such as, structured, semi and non structured documents.\n","\n","XML Parsers:\n","\n","These are techniques that parses xml, html, xhtml document into a nicer structure, like a tree."]},{"cell_type":"markdown","metadata":{"id":"Tm9cImoDyk35","colab_type":"text"},"source":["## Tokenization\n","\n","Goal: split plaint text into basic units, needed for further processing.\n","\n","Depending on the task we have different kind of units.\n","\n","After applying the tokenization we can use a normalization function to translate the acronyms, the abbreviations and some own number for getting and additional information.\n","For example, U.P.C, Universidad Politecnica de Catalunya. Mr. > Mister.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gG2D0IIh1Tm3","colab_type":"text"},"source":["## Sentence splitting\n","\n","It is a subset of tokenization but we are interesting in finding just sentences.\n","\n","Goal: find the boundaries of a sentence in plain text.\n","\n","Main problems:\n","\n","- Internal punctuaction like periods that doesnt means the end of a sentence. \n","\n","Methods:\n","\n","- Hand-crafted rules or Machine Learning methods.\n","\n","But they are too expensive because of the amount of rules.\n","\n","Abbrev. is not common for punkt.\n","\n","However, is a sentence starter."]},{"cell_type":"markdown","metadata":{"id":"ftmFEzK_8AHv","colab_type":"text"},"source":["# Language Identification\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pXA0fOme8DNy","colab_type":"text"},"source":["Goal: it is like a classification problem. Mapping a ducument into languages.\n","\n","MLE can fail because of data sparness.\n","\n","Smoothing techniques:\n","\n","B: is unique.\n"]},{"cell_type":"code","metadata":{"id":"ONL3rRuJxM2v","colab_type":"code","outputId":"9687e3b4-cc25-434a-f734-f88aa20f61b9","executionInfo":{"status":"ok","timestamp":1568888604529,"user_tz":-120,"elapsed":522,"user":{"displayName":"gusseppe bravo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrKgrr2hSym8LKaXEVXh9jB7w8fVgOvWgeNwb5cA=s64","userId":"12474180553255750962"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import math\n","\n","MLE_en = lambda c: c/1.3e\n","log_MLE_en = lambda c: math.log(c/1.3e6)\n","data_en = { 'a': 1.7e4,\n","            'he': 1e4, \n","            'mail': 3.9e3,\n","            'sent': 850,\n","            'to': 25e3,\n","            'mordorian': 0} \n","\n","def calc_mle(sentence):\n","  value = sum([log_MLE_en(data_en[w]) for w in sentence.split()])\n","\n","  return value\n","\n","calc_mle('he sent a mail')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-31.556562485086605"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"DkDTwgNYAKbr","colab_type":"code","outputId":"aa87d266-981d-4c63-8df5-62e8352301ca","executionInfo":{"status":"ok","timestamp":1568888564084,"user_tz":-120,"elapsed":535,"user":{"displayName":"gusseppe bravo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBrKgrr2hSym8LKaXEVXh9jB7w8fVgOvWgeNwb5cA=s64","userId":"12474180553255750962"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["1.7e3 "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1700.0"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"3vy37lVW0nqD","colab_type":"text"},"source":["# Morphology"]},{"cell_type":"markdown","metadata":{"id":"jqWbMmXk3TGO","colab_type":"text"},"source":["IR: information retrieval.\n","Study of the structure of words\n","\n","the infletional morphology is the most common.\n","\n","complex model to make a language model is using the finite state automata.\n","\n","FSA:\n","M: model\n","\n","transducers translates one lang into another.\n","\n","do the exercise weighted edit distance in the pdf "]},{"cell_type":"markdown","metadata":{"id":"g0Z75-Yn2Pu9","colab_type":"text"},"source":["# POS tagging"]},{"cell_type":"markdown","metadata":{"id":"-N7SCLdU5YnS","colab_type":"text"},"source":["- Bayes theory study\n","- Markov chains study\n","- \n","Two possible classifications:\n","\n","- Open class: we can invent new words: social, chat.\n","- Closed class: those words are already invented: car, dog, on, in , etc.\n","\n","- Depending on the applications we need more granularity: for example, verb: base, past, future.\n","\n","The are two kind of methods to deal with tagging:\n","\n","- Rule-based methods: costly, built manually. Brill's tagger (rules learnt from training).\n","- Stochastic methods: Hidden markov model. Viterbi.\n","\n","Stochastic tagger: the idea is to assign the most likely POS-tag to a word.\n","\n","Markov model: \n","\n","Hidden markov model: there unobserved (hidden) states.\n","\n","- Study maximum likehood estimation\n","\n","- HMM is a generative model, not  discriminative model.\n"]},{"cell_type":"code","metadata":{"id":"74Lo4UZoAKrj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}