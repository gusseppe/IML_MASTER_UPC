{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYXOSvo2sVJw"
   },
   "source": [
    "## LAZY LEARNING EXERCISE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "USM3_DR9sVJy",
    "outputId": "b404a26e-ac21-4aa6-b0b0-7f993141c325"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from urllib import request\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tools import eda, all_steps\n",
    "from tools import preprocess as prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FiLw-xusVKR"
   },
   "source": [
    "### Function that automatically reads the files and performs the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DJhGyMtsVKR"
   },
   "outputs": [],
   "source": [
    "X_cat = None\n",
    "X_norm_train = None\n",
    "def read_train_test_files(fold_number):\n",
    "    global X_cat, X_norm_train\n",
    "    import glob\n",
    "    train_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.train.arff') # for sick dataset\n",
    "#     train_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.train.arff') # for bal dataset\n",
    "#     test_arff_files = glob.glob('../datasets/datasetsCBR/bal/*.test.arff') # for bal dataset\n",
    "    test_arff_files = glob.glob('../datasets/datasetsCBR/sick/*.test.arff') # for sick dataset\n",
    "    \n",
    "    TrainTotal = []\n",
    "    Y_TrainTotal = []\n",
    "    \n",
    "    TestTotal = []\n",
    "    Y_TestTotal = []\n",
    "    \n",
    "    cat_features = ['sex', 'on_thyroxine', \n",
    "                    'query_on_thyroxine', 'on_antithyroid_medication',\n",
    "                    'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment',\n",
    "                    'query_hypothyroid', 'query_hyperthyroid', 'lithium',\n",
    "                    'goitre', 'tumor', 'hypopituitary', 'psych',\n",
    "                    'TSH_measured', 'T3_measured', 'TT4_measured',\n",
    "                    'T4U_measured', 'FTI_measured', 'TBG_measured',\n",
    "                    'referral_source'] # for sick dataset\n",
    "    response = 'Class' # for sick dataset\n",
    "#     cat_features = None # for bal dataset\n",
    "#     response = 'class' # for bal dataset\n",
    "    for file in train_arff_files:\n",
    "        \n",
    "\n",
    "        df_train = eda.read_arff(path_data=file, url_data=None)\n",
    "        \n",
    "        X_num, X_cat, y = all_steps.clean_sick(df_train)\n",
    "        X = prep.join_features(X_num, X_cat)\n",
    "\n",
    "#         splits, metadata = eda.split(df_train, cat_features=cat_features,response=response)\n",
    "#         X_num = splits['X_num']\n",
    "#         X_cat = splits['X_cat'] \n",
    "#         X_cat = prep.encode(X_cat)\n",
    "#         y_train = splits['y'][response].values\n",
    "#         X_norm_train = (X_num - X_num.min()) / (X_num.max() - X_num.min())\n",
    "\n",
    "        TrainTotal.append(X.values)\n",
    "        Y_TrainTotal.append(y)\n",
    "        \n",
    "    \n",
    "    for file in test_arff_files: \n",
    "       \n",
    "        df_test = eda.read_arff(path_data=file, url_data=None)\n",
    "        X_num, X_cat, y = all_steps.clean_sick(df_test)\n",
    "        X = prep.join_features(X_num, X_cat)\n",
    "#         splits, metadata = eda.split(df_test, cat_features=cat_features,response=response)\n",
    "#         X_num = splits['X_num']\n",
    "#         X_cat = splits['X_cat'] \n",
    "#         X_cat = prep.encode(X_cat)\n",
    "#         y_test = splits['y'][response].values\n",
    "#         X_norm_test = (X_num - X_num.min()) / (X_num.max() - X_num.min())\n",
    "        TestTotal.append(X.values)\n",
    "        Y_TestTotal.append(y)\n",
    "        \n",
    "        \n",
    "    return TrainTotal[fold_number-1],Y_TrainTotal[fold_number-1], TestTotal[fold_number-1], Y_TestTotal[fold_number-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnWv-DDcsVKT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3395, 53)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_number = 1\n",
    "X_train,y_train, X_test, y_test = read_train_test_files(fold_number)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN provisional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class KIblAlgorithm:\n",
    "    def __init__(self, k=5, r=2, voting='most', retention='nr'):\n",
    "        self.k = k\n",
    "        self.r = r # for minkowski distance\n",
    "        self.voting = voting\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.n_classes = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_classes = len(np.unique(y))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def minskowski(self, x1, x2, r):\n",
    "        \"\"\"Minskowski distance between two points.\"\"\"\n",
    "#         distance =0.0\n",
    "#         for k in range(length):\n",
    "#             distance += (abs(p1[k]-p2[k])**r)\n",
    "\n",
    "#         return distance**(1/r)\n",
    "\n",
    "        distance = np.sum(np.abs(x1-x2) ** r, axis=1) ** (1/r)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def get_policy(self, distances, voting='most'):\n",
    "        \n",
    "        if voting == 'most':\n",
    "            votes = np.zeros(self.n_classes, dtype=np.int)\n",
    "\n",
    "            # find k closet neighbors and vote\n",
    "            # argsort returns the indices that would sort an array\n",
    "            # so indices of nearest neighbors\n",
    "            # we take self.k first\n",
    "            for neighbor_id in np.argsort(distances)[:self.k]:\n",
    "                # this is a label corresponding to one of the closest neighbor\n",
    "                try:\n",
    "                    neighbor_label = self.y[neighbor_id]\n",
    "                # which updates votes array\n",
    "                    votes[neighbor_label] += 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "#             print(votes)\n",
    "            return np.argmax(votes)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        for x in X_test:\n",
    "            distances = self.minskowski(self.X, x, self.r)\n",
    "#             print(distances)\n",
    "            label = self.get_policy(distances, voting=self.voting)\n",
    "            y_pred.append(label)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class reductionKIblAlgorithm:\n",
    "    def __init__(self, k=5, r=2, \n",
    "                 voting='most', \n",
    "                 retention='nr',\n",
    "                 reduction='cnn',\n",
    "                 random_state=42):\n",
    "\n",
    "        self.k = k\n",
    "        self.r = r\n",
    "        self.voting = voting\n",
    "        self.retention = retention\n",
    "        self.reduction = reduction\n",
    "        self.random_state = random_state\n",
    "        self.knn = KIblAlgorithm(k, r, voting, retention)\n",
    "        self.knn_reduced = self.knn\n",
    "        self.indexes_rm = None\n",
    "        self.X_reduced = None\n",
    "        self.y_reduced = None\n",
    "        \n",
    "    def apply_reduction(self, X, y, \n",
    "                        method='cnn', random_state=42):\n",
    "        \n",
    "        random_instance = np.random.RandomState(random_state)\n",
    "        \n",
    "        def cnn(X_train, y_train):\n",
    "            \"\"\"\n",
    "                Incremental algorithm. Begins with random instances \n",
    "                belonging to each class, then increasing the training \n",
    "                data by inserting those instances that misclassified.\n",
    "            \"\"\"\n",
    "            # Start gathering one instance for each class, randomly.\n",
    "            classes = np.unique(y_train)\n",
    "            indexes_reduced = []\n",
    "            for cl in classes:\n",
    "                y_indexes = np.where(y_train == cl)[0]\n",
    "                index = random_instance.choice(y_indexes, 1)[0]\n",
    "                indexes_reduced.append(index)\n",
    "\n",
    "            x_train_reduced = X_train[indexes_reduced]\n",
    "            y_train_reduced = y_train[indexes_reduced]\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "          \n",
    "                # If misclassified, add to reduced set.\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.vstack([x_train_reduced, x_instance])\n",
    "                    y_train_reduced = np.hstack([y_train_reduced, y_instance])\n",
    "                    indexes_reduced = np.hstack([indexes_reduced, index])\n",
    "\n",
    "            # Only unique indexes\n",
    "            indexes_reduced = np.unique(indexes_reduced)\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced\n",
    "        \n",
    "        def enn(X_train, y_train):\n",
    "            \"\"\"\n",
    "                Non-incremental algorithm. Each instance is removed if it \n",
    "                does not agree with the majority of its knn.\n",
    "            \n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "\n",
    "                # If misclassified, remove from the initial set.\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced           \n",
    "        \n",
    "        def ib3(X_train, y_train):\n",
    "            \"\"\"\n",
    "                It is an incremental algorith. It addresses the IB2's problem \n",
    "                of keeping noisy instances by retaining only acceptable \n",
    "                misclassified instances.\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with the first element.\n",
    "            x_train_reduced = np.reshape(X_train[0], (1, -1))\n",
    "            y_train_reduced = np.reshape(y_train[0], (1, -1))\n",
    "            acceptable = np.array([0])\n",
    "            \n",
    "            lower = lambda p,z,n: (p + (z**2)/(2*n) - z*((p*(1-p)/n + (z**2)/(4*n**2)))**0.5)/(1 + (z**2)/n)\n",
    "            upper = lambda p,z,n: (p + (z**2)/(2*n) + z*((p*(1-p)/n + (z**2)/(4*n**2)))**0.5)/(1 + (z**2)/n)\n",
    "               \n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "#                 print(x_train_reduced)\n",
    "                y_pred_instance = best_knn.predict(np.asarray([x_instance]))\n",
    "\n",
    "                # This part is similar to IB2\n",
    "                if y_pred_instance != y_instance:\n",
    "                    x_train_reduced = np.vstack([x_train_reduced, x_instance])\n",
    "                    acceptable = np.hstack([acceptable, index])\n",
    "                \n",
    "                    \n",
    "                incorrect_class = 0\n",
    "                correct_class = 0\n",
    "                # This part differ from IB2, just acceptable instance are kept.\n",
    "                # Count the number of incorrect and correct classification\n",
    "                for x_instance_reduced in x_train_reduced:\n",
    "                    best_knn = self.knn\n",
    "                    best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                    y_pred_instance_reduced = best_knn.predict(np.asarray([x_instance_reduced]))\n",
    "                    \n",
    "                    if y_pred_instance_reduced != y_instance:\n",
    "                        incorrect_class += 1\n",
    "                    else:\n",
    "                        correct_class += 1\n",
    "                \n",
    "                n = incorrect_class + correct_class\n",
    "                p = correct_class / n\n",
    "                \n",
    "                # For acceptance\n",
    "                z = 0.9\n",
    "                lower_bound = lower(p, z, n)\n",
    "                upper_bound = upper(p, z, n)\n",
    "#                 print(lower_bound, upper_bound, incorrect_class, correct_class)\n",
    "                if (incorrect_class/n <= lower_bound) or (correct_class/n >= upper_bound):\n",
    "                    acceptable = np.hstack([acceptable, index])\n",
    "                \n",
    "                # For removing\n",
    "                z = 0.7\n",
    "                lower_bound = lower(p, z, n)\n",
    "                upper_bound = upper(p, z, n)\n",
    "                \n",
    "                if (incorrect_class/n <= lower_bound) or (correct_class/n >= upper_bound):\n",
    "                    acceptable = np.delete(acceptable, [index], axis=0)                 \n",
    "\n",
    "            x_train_reduced = X_train[acceptable]\n",
    "            y_train_reduced = y_train[acceptable]\n",
    "            indexes_reduced = acceptable\n",
    "            \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced    \n",
    "  \n",
    "        def drop1(X_train, y_train):\n",
    "            \"\"\"\n",
    "                This is a non-incremental algorithm. From the paper, \n",
    "                it can be translated as: \"It goes over the dataset in the provided order, \n",
    "                and removes those instances whose removal does not decrease \n",
    "                the accuracy of the 1-NN rule in the remaining dataset\"\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "\n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "#                 print(index)\n",
    "                best_knn = self.knn\n",
    "                best_knn.fit(x_train_reduced, y_train_reduced)\n",
    "                y_pred_initial = best_knn.predict(x_train_reduced)\n",
    "                \n",
    "                acc_initial = accuracy_score(y_pred_initial, y_train_reduced)\n",
    "                \n",
    "\n",
    "                # Removes one instance from the initial set.\n",
    "                x_train_reduced_t = np.delete(x_train_reduced, [index], axis=0)\n",
    "                y_train_reduced_t = np.delete(y_train_reduced, [index], axis=0)\n",
    "                indexes_reduced_t = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "                # Fit again using a 1-nn in the remaining data.\n",
    "                best_1nn = KIblAlgorithm(k=self.k, r=self.r, \n",
    "                                         voting=self.voting, \n",
    "                                         retention=self.retention)\n",
    "                \n",
    "                best_1nn.fit(x_train_reduced_t, y_train_reduced_t)\n",
    "                y_pred_1nn_without_instance = best_1nn.predict(x_train_reduced_t)           \n",
    "                \n",
    "                acc_after = accuracy_score(y_pred_1nn_without_instance, y_train_reduced_t)\n",
    "                \n",
    "                # if accuracy after removing the instance is greater than initial, then \n",
    "                # remove from the initial set.\n",
    "                if acc_after >= acc_initial:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced      \n",
    "        \n",
    "        def drop2(X_train, y_train):\n",
    "            \"\"\"\n",
    "                This is a non-incremental algorithm. Similar to DROP1 but \n",
    "                the accuracy of the 1-NN rule is done in the original dataset\".\n",
    "                \n",
    "                Note: A preprocessing is needed before calculating the accuracy:\n",
    "                \"starts with those which are furthest from their nearest \"enemy\" \n",
    "                (two instances are said to be \"enemies\" if they belong to different classes)\".\n",
    "                Hence, this is a partial implementation of drop2.\n",
    "            \"\"\"\n",
    "            classes = np.unique(y_train)\n",
    "            \n",
    "            # Start with all training data.\n",
    "            indexes_reduced = np.arange(len(X_train))\n",
    "\n",
    "            x_train_reduced = X_train\n",
    "            y_train_reduced = y_train\n",
    "            \n",
    "            \n",
    "            best_knn = self.knn\n",
    "            best_knn.fit(X_train, y_train)\n",
    "            y_pred_initial = best_knn.predict(X_train)\n",
    "            acc_initial = accuracy_score(y_pred_initial, y_train)\n",
    "            \n",
    "            for index, (x_instance, y_instance) in enumerate(zip(X_train, y_train)):\n",
    "\n",
    "\n",
    "                # Removes one instance from the initial set.\n",
    "                x_train_reduced_t = np.delete(x_train_reduced, [index], axis=0)\n",
    "                y_train_reduced_t = np.delete(y_train_reduced, [index], axis=0)\n",
    "                indexes_reduced_t = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "                # Fit again using a 1-nn in the remaining data.\n",
    "                best_1nn = KIblAlgorithm(k=self.k, r=self.r, \n",
    "                                         voting=self.voting, \n",
    "                                         retention=self.retention)\n",
    "                \n",
    "                best_1nn.fit(x_train_reduced_t, y_train_reduced_t)\n",
    "                y_pred_1nn_without_instance = best_1nn.predict(x_train_reduced_t)           \n",
    "                \n",
    "                acc_after = accuracy_score(y_pred_1nn_without_instance, y_train_reduced_t)\n",
    "                \n",
    "                # if accuracy after removing the instance is greater than initial, then \n",
    "                # remove from the initial set.\n",
    "                if acc_after >= acc_initial:\n",
    "                    x_train_reduced = np.delete(x_train_reduced, [index], axis=0)\n",
    "                    y_train_reduced = np.delete(y_train_reduced, [index], axis=0)\n",
    "                    indexes_reduced = np.delete(indexes_reduced, [index], axis=0)\n",
    "                \n",
    "            return x_train_reduced, y_train_reduced, indexes_reduced         \n",
    "        \n",
    "        if method == 'cnn':\n",
    "            return cnn(X, y)\n",
    "        elif method == 'enn':\n",
    "            return enn(X, y)\n",
    "        elif method == 'ib3':\n",
    "            return ib3(X, y)\n",
    "        elif method == 'drop1':\n",
    "            return drop1(X, y)\n",
    "        elif method == 'drop2':\n",
    "            return drop2(X, y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X_reduced, y_reduced, indexes_rm = self.apply_reduction(X, y, \n",
    "                                             self.reduction,\n",
    "                                             self.random_state)\n",
    "        \n",
    "        self.knn_reduced.fit(X_reduced, y_reduced)\n",
    "        \n",
    "        self.X_reduced = X_reduced\n",
    "        self.y_reduced = y_reduced\n",
    "        self.indexes_rm = indexes_rm\n",
    "        \n",
    "        return self\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_pred = self.knn_reduced.predict(X)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing knn vs reduced_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KIblAlgorithm(k=5, r=1, \n",
    "                    voting='most', \n",
    "                    retention='nr')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:185: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:186: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:201: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:202: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:203: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.3 s, sys: 70.9 ms, total: 39.3 s\n",
      "Wall time: 39.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reduced_knn = reductionKIblAlgorithm(k=5, r=1, \n",
    "                    voting='most', \n",
    "                    retention='nr',\n",
    "                    reduction='drop1')\n",
    "reduced_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_reduced = reduced_knn.predict(X_test)\n",
    "accuracy_score(y_pred_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bal_lazy_learning-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
